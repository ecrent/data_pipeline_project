# =============================================================================
# DATA PIPELINE PROJECT - ENVIRONMENT CONFIGURATION
# =============================================================================
# This file contains environment variables for both GitHub Codespaces and WSL

# =============================================================================
# ENVIRONMENT DETECTION
# =============================================================================
# Set this to 'codespaces' when running in GitHub Codespaces, 'local' for WSL
ENVIRONMENT=local

# =============================================================================
# SERVICE PORTS
# =============================================================================
# Core Infrastructure Ports
ZOOKEEPER_PORT=2181
KAFKA_PORT=9092
KAFKA_INTERNAL_PORT=29092

# Storage and Analytics Ports
MINIO_API_PORT=9000
MINIO_CONSOLE_PORT=9001
ELASTICSEARCH_PORT=9200
KIBANA_PORT=5601

# Spark Cluster Ports
SPARK_MASTER_UI_PORT=8080
SPARK_MASTER_PORT=7077
SPARK_WORKER_UI_PORT=8081

# =============================================================================
# KAFKA CONFIGURATION
# =============================================================================
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC=raw_events
KAFKA_PARTITIONS=3
KAFKA_REPLICATION_FACTOR=1
KAFKA_RETENTION_HOURS=168
KAFKA_RETENTION_BYTES=1073741824

# Kafka Producer Configuration
KAFKA_CLIENT_ID=data-pipeline-producer
KAFKA_BATCH_SIZE=16384
KAFKA_LINGER_MS=100
KAFKA_MAX_REQUEST_SIZE=1048576
KAFKA_BUFFER_MEMORY=33554432
KAFKA_RETRIES=5
KAFKA_RETRY_BACKOFF_MS=100

# =============================================================================
# MINIO CONFIGURATION
# =============================================================================
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin123
MINIO_BUCKET=data-lake

# =============================================================================
# ELASTICSEARCH CONFIGURATION
# =============================================================================
ELASTICSEARCH_CLUSTER_NAME=pipeline-cluster
ELASTICSEARCH_NODE_NAME=elasticsearch
ELASTICSEARCH_INDEX=customer_profiles
# WSL-optimized: Reduced memory for systems with 8GB RAM
ES_JAVA_OPTS=-Xms1g -Xmx1g

# =============================================================================
# SPARK CONFIGURATION
# =============================================================================
# Java configuration
JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64

# Spark cluster connection
SPARK_MASTER_URL=spark://localhost:7077

# WSL-optimized: Reduced memory for systems with 8GB RAM
SPARK_WORKER_MEMORY=1G
SPARK_WORKER_CORES=2
SPARK_USER=spark

# Spark application settings
SPARK_APP_NAME=DataPipelineProcessor
SPARK_EXECUTOR_MEMORY=1G
SPARK_EXECUTOR_CORES=2
SPARK_DRIVER_MEMORY=1G

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================
# Data source and processing
SOURCE_FILE=./data/events.csv
BATCH_SIZE=1000
MAX_EVENTS=1000000

# Service Endpoints (for running outside Docker)
SPARK_MASTER_URL=local[2]
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin123
MINIO_BUCKET=data-lake
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_INDEX=customer_profiles

# Output configuration
OUTPUT_PATH=./output
PROCESSED_DATA_BUCKET=processed-data

# Logging and monitoring
LOG_LEVEL=INFO
ENABLE_METRICS=true
METRICS_PORT=8090

# Environment settings
ENVIRONMENT=local
DEBUG=false

# =============================================================================
# NETWORK CONFIGURATION  
# =============================================================================
# WSL-safe subnet that avoids conflicts with Windows networking
NETWORK_SUBNET=172.25.0.0/16
